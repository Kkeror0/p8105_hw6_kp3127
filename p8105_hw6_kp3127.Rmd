---
title: "p8105_hw6_kp3127"
output: html_document
date: "2025-12-02"
---
```{r setup, echo=FALSE}
library(tidyverse)
library(broom)
library(modelr)
library(ggplot2)
library(rvest)
library(patchwork)
library(purrr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
set.seed(1)
```

# Problem 1
Cleaning the dataset 
```{r}
homi_df=read.csv("./homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    victim_age = as.numeric(victim_age),
    solved = if_else(disposition == "Open/No arrest", 0, 1),
  ) %>% 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                       "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age),
    !is.na(victim_sex),
    !is.na(solved)
  ) %>% 
  mutate(
    victim_race = fct_relevel(victim_race, "White"),
    victim_sex  = fct_relevel(victim_sex, "Female")
  )  
```

Logistic regression for Baltimore
```{r}
baltimore_df = homi_df %>% 
  filter(city_state == "Baltimore, MD")

baltimore_fit = 
  glm(
    solved~victim_age + victim_sex + victim_race,
    data   = baltimore_df,
    family = binomial()
  )

baltimore_or =
  baltimore_fit %>% 
  tidy(conf.int = TRUE, exponentiate = TRUE) %>% 
  filter(term == "victim_sexMale") %>% 
  select(term, estimate, conf.low, conf.high)

baltimore_or |> 
  knitr::kable(digits = 3)
```

Logistic regression for all
```{r}
city_or_df <- 
  homi_df |>
  group_by(city_state) |>
  nest() |>
  mutate(
    model = map(
      data,
      ~ .x |>
        mutate(
          victim_sex  = fct_relevel(victim_sex, "Female"),
          victim_race = fct_relevel(victim_race, "White")
        ) |>
        glm(
          solved ~ victim_age + victim_sex + victim_race,
          data   = _,
          family = binomial()
        )
    ),
    results = map(
      model,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) |>
  unnest(results) |>
  filter(term == "victim_sexMale") |>
  select(city_state,estimate,conf.low,conf.high) |>
  arrange(city_state)
```

Plots
```{r}
ggplot(city_or_df, aes(x = city_state, 
                            y = estimate)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high)) +
  geom_hline(yintercept = 1, linetype = "dashed") +
  coord_flip() +
  labs(
    x = "City",
    y = "Adjusted OR (Male vs Female)",
    title = "Adjusted odds ratio of homicide being solved,\ncomparing male vs female victims by city"
  ) +
  theme_minimal() 
```

The estimated odds ratios for solving homicides comparing male with female victims vary substantially across cities. In many cities the point estimates are below 1, suggesting that cases with male victims may be less likely to be solved than those with female victims, although most confidence intervals are wide and include 1, indicating considerable uncertainty. Only a few cities show point estimates clearly above 1. Overall, there is no consistent pattern across all cities, and the wide CIs (especially in some smaller cities) suggest that sex differences in clearance may be modest and imprecisely estimated.

# Problem 2
```{r}
library(p8105.datasets)
data("weather_df")

weather_df %>% 
  drop_na(tmax, tmin, prcp)
```

```{r}
boot_results = 
  weather_df %>% 
  bootstrap(n = 5000, id = "boot_id") %>% 
  mutate(
    model  = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    glance = map(model, glance),
    tidy   = map(model, tidy)
  ) %>% 
  mutate(
    r2 = map_dbl(glance, "r.squared"),
    beta_ratio = map_dbl(
      tidy,
      ~ {
        b1 <- filter(.x, term == "tmin")  %>%  pull(estimate)
        b2 <- filter(.x, term == "prcp") %>%  pull(estimate)
        b1 / b2
      }
    )
  ) %>% 
  select(boot_id, r2, beta_ratio)
```

```{r}
boot_long = 
  boot_results %>% 
  pivot_longer(
    cols = c(r2, beta_ratio),
    names_to = "parameter",
    values_to = "estimate"
  )

ggplot(boot_long, aes(x = estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap(~ parameter, scales = "free") +
  labs(
    x = "Bootstrap estimate",
    y = "Count",
    title = "Bootstrap distributions of R² and β1 / β2"
  ) +
  theme_minimal()
```

```{r}
boot_CI = 
  boot_results %>% 
  summarize(
    r2_lower   = quantile(r2, 0.025),
    r2_upper   = quantile(r2, 0.975),
    ratio_lower = quantile(beta_ratio, 0.025),
    ratio_upper = quantile(beta_ratio, 0.975)
  ) 
boot_CI %>% 
  knitr::kable(digits = 3)
```

The bootstrap distribution of R² is approximately symmetric and tightly concentrated around 0.94, indicating that the model consistently explains a large proportion of the variability in daily maximum temperature. The 95% bootstrap CI for R² is (0.934, 0.947), so in repeated samples we would expect R² to fall in roughly this 93–95% range.

The distribution of β1 / β2 is wider and slightly skewed, with all values negative. The 95% bootstrap CI for the slope ratio is (−279.745 −125.69), suggesting that the coefficients for tmin and precipitation have opposite signs and that the magnitude of their ratio is large but estimated with more uncertainty than R².

# Problem 3
Clean the data
```{r}
birthweight_df=read_csv("./birthweight.csv") %>% 
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform),
  )
```

Propose my own regression model for birthweight:
I aimed to include variables that reflect infant size at birth, gestational age, and maternal characteristics that plausibly influence fetal growth. 
```{r}
bw_main <- lm(
  bwt ~ bhead + blength + babysex + gaweeks +
    ppbmi + wtgain + momage + smoken + mrace,
  data = birthweight_df
)
summary(bw_main)
```

The model explains roughly 71% of the variability in birthweight (djusted R² = 0.713), which indicates fairly strong explanatory power. The overall F-test is highly significant (F(11, 4330) = 982.4, p < 0.001), providing strong evidence that the set of predictors jointly improves prediction of birthweight compared with an intercept-only model.
```{r}
bw_main_aug <- 
  birthweight_df |>
  add_predictions(bw_main) |>
  add_residuals(bw_main)

ggplot(bw_main_aug, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted values",
    y = "Residuals",
    title = "Residuals vs fitted values for main birthweight model"
  ) +
  theme_minimal()
```

The residuals are generally centered around zero across the range of fitted birthweights, and there is no strong curvature or systematic pattern, which supports the linearity assumption. The spread of residuals is fairly constant for most fitted values, although there are a few extreme outliers at very low and very high fitted birthweights. 

Compare my model to two models
```{r}
mod_A <- lm(bwt ~ blength + gaweeks, data = birthweight_df)

mod_B <- lm(bwt ~ bhead * blength * babysex, data = birthweight_df)

mod_C <- bw_main

```

CV
```{r}
cv_df <- 
  crossv_mc(birthweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test  = map(test,  as_tibble),
    mod_A = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    mod_B = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    mod_C = map(train, ~ lm(
      bwt ~ bhead + blength + babysex + gaweeks +
        ppbmi + wtgain + momage + smoken + mrace,
      data = .x
    )),
    rmse_A = map2_dbl(mod_A, test, ~ rmse(.x, .y)),
    rmse_B = map2_dbl(mod_B, test, ~ rmse(.x, .y)),
    rmse_C = map2_dbl(mod_C, test, ~ rmse(.x, .y))
  )

cv_long = 
  cv_df %>% 
  select(starts_with("rmse_")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) %>% 
  mutate(model = recode(model,
                        rmse_A = "A: blength + gaweeks",
                        rmse_B = "B: bhead*blength*babysex",
                        rmse_C = "C: my model"))
```

```{r}
cv_summary = 
  cv_long %>% 
  group_by(model) %>% 
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse)
  )

cv_summary %>% 
  knitr::kable()

ggplot(cv_long, aes(x = model, y = rmse)) +
  geom_boxplot() +
  labs(
    x = "Model",
    y = "RMSE",
    title = "Cross-validated prediction error for three birthweight models"
  ) +
  theme_minimal()
```

The cross-validated RMSEs show clear differences in out-of-sample performance across the three models. Model A, which only includes birth length and gestational age, has the highest prediction error (mean RMSE = 332) and the greatest variability, suggesting substantial underfitting. Model B, which includes head circumference, birth length, infant sex, and their interactions, performs better (mean RMSE = 288). My proposed model (Model C) has the lowest mean RMSE (mean RMSE = 275) and the tightest distribution, indicating the best and most stable predictive performance. Overall, adding additional maternal and infant covariates in Model C improves prediction beyond both the very simple model and the interaction-only model.